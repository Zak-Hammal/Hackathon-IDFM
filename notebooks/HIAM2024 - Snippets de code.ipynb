{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/logo_simple.png\" alt=\"logo\" width=\"400\"/>\n",
    "\n",
    "# Snippets de code \n",
    "\n",
    "Ces snippets de code vont vous permettre de gagner du temps dans la prise en main des ressources à disposition et de l'écosystème data d'île-de-France Mobilités. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appel d'API PRIM : exemple de demande de calcul d'itinéraire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests.auth import HTTPBasicAuth\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "#Affectation des coordonnées au départ et à l'arrivée\n",
    "dlong = \"2.33792\"\n",
    "dlat = \"48.85827\"\n",
    "along = \"2.3588523\"\n",
    "alat = \"48.9271087\"\n",
    "\n",
    "#Date et heure du trajet\n",
    "jour = \"20241121T073000\"\n",
    "\n",
    "#URL de l'API \n",
    "destination = dlong + \"%3B%20\" + dlat + \"&to=\" + along + \"%3B%20\" + alat + \"&datetime=\" + jour\n",
    "url = 'https://prim.iledefrance-mobilites.fr/marketplace/v2/navitia/journeys?from=' + destination\n",
    "\n",
    "#Le header doit contenir la clé API : apikey, remplacer #VOTRE CLE API par votre clé API\n",
    "headers = {'Accept': 'application/json', 'apikey': '#VOTRE CLE API'}\n",
    "\n",
    "#Envoi de la requête au serveur\n",
    "req = requests.get(url, headers=headers)\n",
    "\n",
    "#Affichage du code réponse\n",
    "print('Status:',req)\n",
    "\n",
    "#Lecture du json\n",
    "data = pd.json_normalize(req.json())\n",
    "\n",
    "#Les différents trajets retournés sont dans data['journeys'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appel d'API PRIM : passage du token et appel d'un endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import requests\n",
    "\n",
    "# Clé d'API pour IDFM - Obtention possible via le portail PRIM\n",
    "api_idfm_api_key = \"xxx\"\n",
    "\n",
    "# Paramétrage de l'appel\n",
    "id_ligne_idfm = 'C01742'; #RER A\n",
    "api_idfm_url = f\"https://prim.iledefrance-mobilites.fr/marketplace/general-message?LineRef=STIF%3ALine%3A%3A{id_ligne_idfm}%3A\"\n",
    "headers = {\n",
    "    \"apiKey\": api_idfm_api_key\n",
    "}\n",
    "\n",
    "# Effectuer une requête GET avec l'en-tête contenant la clé d'API IDFM\n",
    "response = requests.get(api_idfm_url, headers=headers)\n",
    "\n",
    "# Extraction de la réponse au format json\n",
    "try:\n",
    "    if response.status_code == 200:\n",
    "        # Extraire le JSON de la réponse\n",
    "        json_data = response.json()\n",
    "        # Vous pouvez afficher le JSON pour le vérifier\n",
    "        print(json_data)\n",
    "    else:\n",
    "        print(\"Échec de la requête HTTP. Statut de réponse :\", response.status_code)\n",
    "except Exception as e:\n",
    "    print(\"Une erreur s'est produite :\", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Onyxia : Lecture d'un fichier sur l'espace de stockage partagé (voir aussi notebook dédié)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation des dépendances :\n",
    "!pip install s3fs\n",
    "\n",
    "# import des dépendances\n",
    "import os\n",
    "import s3fs\n",
    "\n",
    "# Creation d'un objet filesystem, les variables d'environnement on été automatiquement traitées par Onyxia\n",
    "S3_ENDPOINT_URL = \"https://\" + os.environ[\"AWS_S3_ENDPOINT\"]\n",
    "fs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': S3_ENDPOINT_URL})\n",
    "\n",
    "# Liste des documents du répertoire partagé dédié au hackathon :\n",
    "fs.ls(\"dlb-hackathon/datasets-diffusion\", refresh=True)\n",
    "\n",
    "# Lecture d'un fichier csv et chargement en DataFrame Panda : \n",
    "import pandas as pd\n",
    "\n",
    "BUCKET = \"dlb-hackathon\"\n",
    "FILE_KEY_S3 = \"datasets-diffusion/ascenseurs_historique_etat/RELEVES_ETATS_ASCENSEURS_SNCF_RATP.parquet\"\n",
    "FILE_PATH_S3 = BUCKET + \"/\" + FILE_KEY_S3\n",
    "\n",
    "with fs.open(FILE_PATH_S3, mode=\"rb\") as file_in:\n",
    "    df = pd.read_parquet(file_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Onyxia : Ecriture d'un fichier sur l'espace de stockage partagé (voir aussi notebook dédié)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On peut uploader par une commande terminal\n",
    "!mc cp ./fichier_exemple.parquet s3/dlb-deptdata/SHARED_DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer un code ligne en un identifiant de ligne SIRI pour les appels d'API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion de l'id_ligne du référentiel des lignes en id compatible avec les API, les \"deux points\" finaux sont indispensables\n",
    "code_ligne_idfm = 'C01742'; #RER A\n",
    "id_ligne_idfm = \"STIF:Line::{id_ligne_idfm}:\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer un code arrêt en un identifiant d'arrêt SIRI pour les appels d'API. \n",
    "Note : les identifiant d'arrêts à prendre en compte sont en général les id de zones d'arrêt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion de ZdAId du référentiel des arrêts en id compatible avec les API, les \"deux points\" finaux sont indispensables\n",
    "code_zone_arret_idfm = '42135'; #Les Dix Arpents\n",
    "id_arret_idfm = \"STIF:monomodalStopPlace::{code_zone_arret_idfm }:\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilisation de modèles ouverts sur Hugging Face en local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installation de la version python locale d'ollama (llama-cpp)\n",
    "!pip install llama-cpp-python\n",
    "\n",
    "# installation du client hugging face (Le Github de l'IA)\n",
    "!pip install -U \"huggingface_hub[cli]\"\n",
    "\n",
    "# Chargement de llama-cpp\n",
    "from llama_cpp import Llama\n",
    "# Cette instruction minimale permet de sélectionner le modèle et son niveau de compression, le téléchargement le paramétrage et la mise en mémoire (CPU), sont automatiques :\n",
    "llm = Llama.from_pretrained(\n",
    "        repo_id=\"bartowski/gemma-2-2b-it-GGUF\", #Plus gros dépôt de LLM libres de Hugging face : https://huggingface.co/bartowski\n",
    "        filename=\"gemma-2-2b-it-Q6_K_L.gguf\", # Attention a prendre des modèles de taille <= 6Go pour des performances raisonnables, pas de garantie de fonctionnement au delà \n",
    " n_ctx=4096,\n",
    " verbose=False,\n",
    ")\n",
    "\n",
    "# Une fois le LLM chargé (environ une minute par Go), il peut être appelé, via une fonction *completion, ici pour un chatbot :\n",
    "llm_response = llm.create_chat_completion(\n",
    "        messages = [\n",
    "                {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": \"###SYSTEM : You are the Capital assistant. I give you a country, you give me the capital and try to retrieve the country iso code. ### FORMAT : Capital=<name of the Capital> CODE=<ISO CODE 2 CHARS>\n",
    "                },\n",
    "                {\n",
    "                        \"role\": \"assistant\",\n",
    "                        \"content\": \"OK, I understand. If you say France, i say Capital=Paris CODE=FR\n",
    "                },\n",
    "                {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": \"Germany\"\n",
    "                }\n",
    "        ]\n",
    ")\n",
    "\n",
    "# La réponse du LLM est pleine de métadonnées, mais le message texte peut être extrait de cette manière simple :\n",
    "print(llm_response['choices'][0]['message']['content'])\n",
    "# Capital=Berlin CODE=DE\n",
    "\n",
    "#Exemple avec un autre LLM :\n",
    "llm2 = Llama.from_pretrained(\n",
    "        repo_id=\"bartowski/Llama-3.2-3B-Instruct-GGUF\", #Plus gros dépôt de LLM libres de Hugging face : https://huggingface.co/bartowski\n",
    "        filename=\"Llama-3.2-3B-Instruct-Q5_K_M.gguf\", # Attention a prendre des modèles de taille <= 6Go pour des performances raisonnables, pas de garantie de fonctionnement au delà \n",
    " n_ctx=4096,\n",
    " verbose=False,\n",
    ")\n",
    "llm_response2 = llm2.create_chat_completion(\n",
    "        messages = [\n",
    "                {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": \"###SYSTEM : You are the Capital assistant. I give you a country, you give me the capital and try to retrieve the country iso code. ### FORMAT : Capital=<name of the Capital> CODE=FR\"\n",
    "                },\n",
    "                {\n",
    "                        \"role\": \"assistant\",\n",
    "                        \"content\": \"OK, I understand. If you say France, i say Capital=Paris CODE=FR\"\n",
    "                },\n",
    "                {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": \"Germany\"\n",
    "                }\n",
    "        ]\n",
    ")\n",
    "print(llm_response2['choices'][0]['message']['content'])\n",
    "# Capital=Cologne CODE=DE ## no comment :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
